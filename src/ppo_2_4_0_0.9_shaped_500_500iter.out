nohup: ignoring input
2024-11-29 11:06:56,685	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:56,694	WARNING __init__.py:10 -- DDPG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,572	INFO worker.py:1673 -- Started a local Ray instance.
2024-11-29 11:06:58,926	INFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
2024-11-29 11:06:58,928	WARNING __init__.py:10 -- A3C has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,928	WARNING __init__.py:10 -- A2C has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,930	WARNING __init__.py:10 -- AlphaZero has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,932	WARNING __init__.py:10 -- ApexDQN has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,933	WARNING __init__.py:10 -- ApexDDPG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,936	WARNING __init__.py:10 -- ES has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,937	WARNING __init__.py:10 -- ARS has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,940	WARNING __init__.py:10 -- BanditLinTS and BanditLinUCB has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,946	WARNING __init__.py:10 -- CRR has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,947	WARNING __init__.py:10 -- DDPPO has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,950	WARNING __init__.py:8 -- `Dreamer(V1)` has been removed from RLlib and will no longer be maintained by the RLlib team. Use `DreamerV3` instead, which is part of the RLlib library and will continue to be maintained and supported in the future. See https://github.com/ray-project/ray/tree/master/rllib/algorithms/dreamerv3 for more information on our DreamerV3 implementation.
/local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  gym.logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
2024-11-29 11:06:58,966	WARNING __init__.py:10 -- DT has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,974	WARNING __init__.py:10 -- AlphaStar has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,976	WARNING __init__.py:10 -- MADDDPG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,977	WARNING __init__.py:10 -- MAML has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,979	WARNING __init__.py:10 -- MBMPO has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,981	WARNING __init__.py:10 -- QMIX has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,983	WARNING __init__.py:10 -- R2D2 has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,987	WARNING __init__.py:10 -- SlateQ has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,987	WARNING __init__.py:10 -- TD3 has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2024-11-29 11:06:58,989	WARNING __init__.py:10 -- LeelaChessZero has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[36m(pid=198224)[0m 2024-11-29 11:07:01,832	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[33m(raylet)[0m bash: /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/libtinfo.so.6: no version information available (required by bash)
[36m(RolloutWorker pid=199858)[0m /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
[36m(RolloutWorker pid=199858)[0m   warnings.warn(
[36m(RolloutWorker pid=199858)[0m /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
[36m(RolloutWorker pid=199858)[0m   warnings.warn(
Number of GPUS available:  2.0
Agents are limited in their observation, they can see with a radius of 0.9
Training PPO model...
╭────────────────────────────────────────────────────────────╮
│ Configuration for experiment     PPO_2024-11-29_11-06-58   │
├────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator     │
│ Scheduler                        FIFOScheduler             │
│ Number of trials                 1                         │
╰────────────────────────────────────────────────────────────╯

View detailed results here: /local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58
To visualize your results with TensorBoard, run: `tensorboard --logdir /local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58`

Trial status: 1 PENDING
Current time: 2024-11-29 11:06:59. Total running time: 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭──────────────────────────────────────────╮
│ Trial name                      status   │
├──────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   PENDING  │
╰──────────────────────────────────────────╯

Trial PPO_simple_tag_v3_f65f1_00000 started with configuration:
╭───────────────────────────────────────────────────────────────────────────╮
│ Trial PPO_simple_tag_v3_f65f1_00000 config                                │
├───────────────────────────────────────────────────────────────────────────┤
│ _AlgorithmConfig__prior_exploration_config/type        StochasticSampling │
│ _disable_action_flattening                                          False │
│ _disable_execution_plan_api                                          True │
│ _disable_initialize_loss_from_dummy_batch                           False │
│ _disable_preprocessor_api                                           False │
│ _enable_learner_api                                                  True │
│ _enable_rl_module_api                                                True │
│ _fake_gpus                                                          False │
│ _is_atari                                                                 │
│ _learner_class                                                            │
│ _tf_policy_handles_more_than_one_loss                               False │
│ action_mask_key                                               action_mask │
│ action_space                                                              │
│ actions_in_input_normalized                                         False │
│ always_attach_evaluation_results                                    False │
│ auto_wrap_old_gym_envs                                               True │
│ batch_mode                                              truncate_episodes │
│ callbacks                                            ...efaultCallbacks'> │
│ checkpoint_trainable_policies_only                                  False │
│ clip_actions                                                        False │
│ clip_param                                                            0.3 │
│ clip_rewards                                                              │
│ compress_observations                                               False │
│ count_steps_by                                                  env_steps │
│ create_env_on_driver                                                False │
│ custom_eval_function                                                      │
│ delay_between_worker_restarts_s                                       60. │
│ disable_env_checking                                                False │
│ eager_max_retraces                                                     20 │
│ eager_tracing                                                        True │
│ enable_async_evaluation                                             False │
│ enable_connectors                                                    True │
│ enable_tf1_exec_eagerly                                             False │
│ entropy_coeff                                                          0. │
│ entropy_coeff_schedule                                                    │
│ env                                                         simple_tag_v3 │
│ env_runner_cls                                                            │
│ env_task_fn                                                               │
│ evaluation_config                                                         │
│ evaluation_duration                                                    10 │
│ evaluation_duration_unit                                         episodes │
│ evaluation_interval                                                       │
│ evaluation_num_workers                                                  0 │
│ evaluation_parallel_to_training                                     False │
│ evaluation_sample_timeout_s                                          180. │
│ explore                                                              True │
│ export_native_model_files                                           False │
│ fake_sampler                                                        False │
│ framework                                                           torch │
│ gamma                                                                0.95 │
│ grad_clip                                                                 │
│ grad_clip_by                                                  global_norm │
│ ignore_worker_failures                                              False │
│ in_evaluation                                                       False │
│ input                                                             sampler │
│ keep_per_episode_custom_metrics                                     False │
│ kl_coeff                                                              0.2 │
│ kl_target                                                            0.01 │
│ lambda                                                                 1. │
│ local_gpu_idx                                                           0 │
│ local_tf_session_args/inter_op_parallelism_threads                      8 │
│ local_tf_session_args/intra_op_parallelism_threads                      8 │
│ log_level                                                            WARN │
│ log_sys_usage                                                        True │
│ logger_config                                                             │
│ logger_creator                                                            │
│ lr                                                                 0.0001 │
│ lr_schedule                                                               │
│ max_num_worker_restarts                                              1000 │
│ max_requests_in_flight_per_sampler_worker                               2 │
│ metrics_episode_collection_timeout_s                                  60. │
│ metrics_num_episodes_for_smoothing                                    100 │
│ min_sample_timesteps_per_iteration                                      0 │
│ min_time_s_per_iteration                                                  │
│ min_train_timesteps_per_iteration                                       0 │
│ model/_disable_action_flattening                                    False │
│ model/_disable_preprocessor_api                                     False │
│ model/_time_major                                                   False │
│ model/_use_default_native_models                                       -1 │
│ model/always_check_shapes                                           False │
│ model/attention_dim                                                    64 │
│ model/attention_head_dim                                               32 │
│ model/attention_init_gru_gate_bias                                    2.0 │
│ model/attention_memory_inference                                       50 │
│ model/attention_memory_training                                        50 │
│ model/attention_num_heads                                               1 │
│ model/attention_num_transformer_units                                   1 │
│ model/attention_position_wise_mlp_dim                                  32 │
│ model/attention_use_n_prev_actions                                      0 │
│ model/attention_use_n_prev_rewards                                      0 │
│ model/conv_activation                                                relu │
│ model/conv_filters                                                        │
│ model/custom_action_dist                                                  │
│ model/custom_model                                                        │
│ model/custom_preprocessor                                                 │
│ model/dim                                                              84 │
│ model/encoder_latent_dim                                                  │
│ model/fcnet_activation                                               tanh │
│ model/fcnet_hiddens                                            [256, 256] │
│ model/framestack                                                     True │
│ model/free_log_std                                                  False │
│ model/grayscale                                                     False │
│ model/lstm_cell_size                                                  256 │
│ model/lstm_use_prev_action                                          False │
│ model/lstm_use_prev_action_reward                                      -1 │
│ model/lstm_use_prev_reward                                          False │
│ model/max_seq_len                                                      20 │
│ model/no_final_linear                                               False │
│ model/post_fcnet_activation                                          relu │
│ model/post_fcnet_hiddens                                               [] │
│ model/use_attention                                                 False │
│ model/use_lstm                                                      False │
│ model/vf_share_layers                                               False │
│ model/zero_mean                                                      True │
│ normalize_actions                                                    True │
│ num_consecutive_worker_failures_tolerance                             100 │
│ num_cpus_for_driver                                                     1 │
│ num_cpus_per_learner_worker                                             1 │
│ num_cpus_per_worker                                                     1 │
│ num_envs_per_worker                                                     1 │
│ num_gpus                                                                0 │
│ num_gpus_per_learner_worker                                             0 │
│ num_gpus_per_worker                                                     0 │
│ num_learner_workers                                                     0 │
│ num_sgd_iter                                                           30 │
│ num_workers                                                             7 │
│ observation_filter                                               NoFilter │
│ observation_fn                                                            │
│ observation_space                                                         │
│ offline_sampling                                                    False │
│ ope_split_batch_by_episode                                           True │
│ output                                                                    │
│ output_compress_columns                                ['obs', 'new_obs'] │
│ output_max_file_size                                             67108864 │
│ placement_strategy                                                   PACK │
│ policies/default_policy                              ...None, None, None) │
│ policies_to_train                                                         │
│ policy_map_cache                                                       -1 │
│ policy_map_capacity                                                   100 │
│ policy_mapping_fn                                    ...t 0x7f9ef2f89e10> │
│ policy_states_are_swappable                                         False │
│ postprocess_inputs                                                  False │
│ preprocessor_pref                                                deepmind │
│ recreate_failed_workers                                             False │
│ remote_env_batch_wait_ms                                                0 │
│ remote_worker_envs                                                  False │
│ render_env                                                          False │
│ replay_sequence_length                                                    │
│ restart_failed_sub_environments                                     False │
│ rl_module_spec                                                            │
│ rollout_fragment_length                                              auto │
│ sample_async                                                        False │
│ sample_collector                                     ...leListCollector'> │
│ sampler_perf_stats_ema_coef                                               │
│ seed                                                                      │
│ sgd_minibatch_size                                                    128 │
│ shuffle_buffer_size                                                     0 │
│ shuffle_sequences                                                    True │
│ simple_optimizer                                                       -1 │
│ sync_filters_on_rollout_workers_timeout_s                             60. │
│ synchronize_filters                                                    -1 │
│ tf_session_args/allow_soft_placement                                 True │
│ tf_session_args/device_count/CPU                                        1 │
│ tf_session_args/gpu_options/allow_growth                             True │
│ tf_session_args/inter_op_parallelism_threads                            2 │
│ tf_session_args/intra_op_parallelism_threads                            2 │
│ tf_session_args/log_device_placement                                False │
│ torch_compile_learner                                               False │
│ torch_compile_learner_dynamo_backend                             inductor │
│ torch_compile_learner_dynamo_mode                                         │
│ torch_compile_learner_what_to_compile                ...ile.FORWARD_TRAIN │
│ torch_compile_worker                                                False │
│ torch_compile_worker_dynamo_backend                                onnxrt │
│ torch_compile_worker_dynamo_mode                                          │
│ train_batch_size                                                     1024 │
│ update_worker_filter_stats                                           True │
│ use_critic                                                           True │
│ use_gae                                                              True │
│ use_kl_loss                                                          True │
│ use_worker_filter_stats                                              True │
│ validate_workers_after_construction                                  True │
│ vf_clip_param                                                         10. │
│ vf_loss_coeff                                                          1. │
│ vf_share_layers                                                        -1 │
│ worker_cls                                                             -1 │
│ worker_health_probe_timeout_s                                          60 │
│ worker_restore_timeout_s                                             1800 │
╰───────────────────────────────────────────────────────────────────────────╯[36m(PPO pid=198224)[0m Install gputil for GPU system monitoring.
[36m(PPO pid=198224)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58/PPO_simple_tag_v3_f65f1_00000_0_2024-11-29_11-06-59/checkpoint_000000)
[36m(RolloutWorker pid=199886)[0m 2024-11-29 11:07:04,829	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(RolloutWorker pid=199886)[0m /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:144: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.[32m [repeated 6x across cluster][0m
[36m(RolloutWorker pid=199886)[0m   warnings.warn([32m [repeated 12x across cluster][0m
[36m(RolloutWorker pid=199886)[0m /local/scratch/a/jshreeku/miniconda3/envs/project_env_rl/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:158: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.[32m [repeated 6x across cluster][0m


Trial status: 1 RUNNING
Current time: 2024-11-29 11:07:29. Total running time: 30s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING         3            17.7269   3072        nan                    nan                    nan                  nan                      0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:07:59. Total running time: 1min 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING         9            52.9473   9216      -6053               -65.2747               -10772.9                  500                      0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:08:29. Total running time: 1min 30s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        14            82.3273   14336   -2592.01                1915.53               -10772.9                  500                      7 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:08:59. Total running time: 2min 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
[36m(PPO pid=198224)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58/PPO_simple_tag_v3_f65f1_00000_0_2024-11-29_11-06-59/checkpoint_000001)
[36m(PPO pid=198224)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58/PPO_simple_tag_v3_f65f1_00000_0_2024-11-29_11-06-59/checkpoint_000002)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        19             111.87   19456   -1712.62                2268.43               -10772.9                  500                      0 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:09:29. Total running time: 2min 30s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        24            141.451   24576   -585.337                3046.74               -10772.9                  500                      7 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:09:59. Total running time: 3min 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        29            171.014   29696   -189.672                3367.08               -10772.9                  500                      0 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:10:29. Total running time: 3min 30s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
[36m(PPO pid=198224)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58/PPO_simple_tag_v3_f65f1_00000_0_2024-11-29_11-06-59/checkpoint_000003)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        34             200.57   34816    124.496                3367.08               -10772.9                  500                      0 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:10:59. Total running time: 4min 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        39            230.169   39936    608.521                 3608.3               -10772.9                  500                      0 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:11:29. Total running time: 4min 30s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name                      status       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ PPO_simple_tag_v3_f65f1_00000   RUNNING        44            259.702   45056    787.759                3616.99               -10772.9                  500                      0 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-11-29 11:11:59. Total running time: 5min 0s
Logical resource usage: 8.0/8 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:L40S)
[36m(PPO pid=198224)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/local/scratch/a/jshreeku/ece595_reinforcement_learning/results/ppo_2_4_0_0.9_shaped_500_500iter/ppo/PPO_2024-11-29_11-06-58/PPO_simple_tag_v3_f65f1_00000_0_2024-11-29_11-06-59/checkpoint_000004)
[33m(raylet)[0m [2024-11-29 11:12:18,157 E 197201 197257] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-11-29_11-06-56_822915_195516 is over 95% full, available space: 162287616; capacity: 3247439872. Object creation will fail if spilling is required.
[33m(raylet)[0m [2024-11-29 11:12:28,162 E 197201 197257] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-11-29_11-06-56_822915_195516 is over 95% full, available space: 162152448; capacity: 3247439872. Object creation will fail if spilling is required.
